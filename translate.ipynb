{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformer import Transformer\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom peft import LoraConfig, get_peft_model\\nlora_config = LoraConfig(\\n    r=8,  # Rangos bajos para LoRA\\n    lora_alpha=16,\\n    lora_dropout=0.1,\\n    target_modules= ['W_q', 'W_k', 'W_v', 'W_o']\\n)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from peft import LoraConfig, get_peft_model\n",
    "# Configurar LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Rango bajo para LoRA\n",
    "    lora_alpha=32,  # Factor de escala\n",
    "    lora_dropout=0.1,  # Dropout\n",
    "    #bias=\"none\",  # Bias para LoRA \n",
    "    target_modules= ['W_q', 'W_k', 'W_v', 'W_o']\n",
    ")\n",
    "'''\n",
    "\n",
    "'''\n",
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "print(device)\n",
    "'''\n",
    "\n",
    "'''\n",
    "from peft import LoraConfig, get_peft_model\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Rangos bajos para LoRA\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules= ['W_q', 'W_k', 'W_v', 'W_o']\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # \"encoder.layers.*.self_attn.W_q\",  \n",
    " #   \"encoder.layers.*.self_attn.W_k\",  \n",
    " #   \"encoder.layers.*.self_attn.W_v\",  \n",
    " #   \"encoder.layers.*.self_attn.W_o\",  \n",
    " #   \"decoder.layers.*.self_attn.W_q\",\n",
    " #   \"decoder.layers.*.self_attn.W_k\",\n",
    " #   \"decoder.layers.*.self_attn.W_v\",\n",
    " #   \"decoder.layers.*.self_attn.W_o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "#ignorar (es original del video)\n",
    "torch.manual_seed(23)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../datasets/idiomas-engl-span.tsv'\n",
    "\n",
    "with open(PATH, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "pairs_engl_span = [line.strip().split('\\t') for line in lines if '\\t' in line]\n",
    "#print(pairs_engl_span[:5])\n",
    "\n",
    "engl_sentences = [pair[1] for pair in pairs_engl_span]\n",
    "span_sentences = [pair[3] for pair in pairs_engl_span]\n",
    "#print(engl_sentences[:10])\n",
    "#print(span_sentences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265486\n",
      "265486\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[á]+\", \"a\", sentence)\n",
    "    sentence = re.sub(r\"[é]+\", \"e\", sentence)\n",
    "    sentence = re.sub(r\"[í]+\", \"i\", sentence)\n",
    "    sentence = re.sub(r\"[ó]+\", \"o\", sentence)\n",
    "    sentence = re.sub(r\"[ú]+\", \"u\", sentence)\n",
    "    sentence = re.sub(r\"[^a-z]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = '<sos> ' + sentence + ' <eos>'\n",
    "    return sentence\n",
    "#s1 = '¿Hola @ cómo estás? 123'\n",
    "#print(s1)\n",
    "#print(preprocess_sentence(s1))\n",
    "\n",
    "engl_sentences = [preprocess_sentence(sentence) for sentence in engl_sentences]\n",
    "span_sentences = [preprocess_sentence(sentence) for sentence in span_sentences]\n",
    "#print(engl_sentences[:10])\n",
    "#print(span_sentences[:10])\n",
    "print(len(engl_sentences))\n",
    "print(len(span_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences):\n",
    "    words = [word for sentence in sentences for word in sentence.split()]\n",
    "    word_count = Counter(words)\n",
    "    sorted_word_counts = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n",
    "    word2idx = {word: idx for idx, (word, _) in enumerate(sorted_word_counts, 2)}\n",
    "    word2idx['<pad>'] = 0\n",
    "    word2idx['<unk>'] = 1\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_word2idx, eng_idx2word = build_vocab(engl_sentences)\n",
    "spa_word2idx, spa_idx2word = build_vocab(span_sentences)\n",
    "eng_vocab_size = len(eng_word2idx)\n",
    "spa_vocab_size = len(spa_word2idx)\n",
    "#print(eng_vocab_size, spa_vocab_size)\n",
    "#print(eng_idx2word)\n",
    "#print(spa_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EngSpaDataset(Dataset):\n",
    "    def __init__(self, eng_sentences, spa_sentences, eng_word2idx, spa_word2idx):\n",
    "        self.eng_sentences = eng_sentences\n",
    "        self.spa_sentences = spa_sentences\n",
    "        self.eng_word2idx = eng_word2idx\n",
    "        self.spa_word2idx = spa_word2idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.eng_sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        eng_sentence = self.eng_sentences[idx]\n",
    "        spa_sentence = self.spa_sentences[idx]\n",
    "        # return tokens idxs\n",
    "        eng_idxs = [self.eng_word2idx.get(word, self.eng_word2idx['<unk>']) for word in eng_sentence.split()]\n",
    "        spa_idxs = [self.spa_word2idx.get(word, self.spa_word2idx['<unk>']) for word in spa_sentence.split()]\n",
    "        \n",
    "        return torch.tensor(eng_idxs), torch.tensor(spa_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    eng_batch, spa_batch = zip(*batch)\n",
    "    eng_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in eng_batch]\n",
    "    spa_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in spa_batch]\n",
    "    eng_batch = torch.nn.utils.rnn.pad_sequence(eng_batch, batch_first=True, padding_value=0)\n",
    "    spa_batch = torch.nn.utils.rnn.pad_sequence(spa_batch, batch_first=True, padding_value=0)\n",
    "    return eng_batch, spa_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, loss_function, optimiser, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0 \n",
    "        for i, (eng_batch, spa_batch) in enumerate(dataloader):\n",
    "            eng_batch = eng_batch.to(device)\n",
    "            spa_batch = spa_batch.to(device)\n",
    "            # Decoder preprocessing\n",
    "            target_input = spa_batch[:, :-1]\n",
    "            target_output = spa_batch[:, 1:].contiguous().view(-1)\n",
    "            # Zero grads\n",
    "            optimiser.zero_grad()\n",
    "            # run model\n",
    "            output = model(eng_batch, target_input)\n",
    "            output = output.view(-1, output.size(-1))\n",
    "            # loss\\\n",
    "            loss = loss_function(output, target_output)\n",
    "            # gradient and update parameters\n",
    "            loss.backward()\n",
    "            #accelerator.backward(loss) #para accelerate\n",
    "            optimiser.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss/len(dataloader)\n",
    "        print(f'Epoch: {epoch}/{epochs}, Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32#64\n",
    "dataset = EngSpaDataset(engl_sentences, span_sentences, eng_word2idx, spa_word2idx)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(d_model=512, num_heads=8, d_ff=2048, num_layers=6,\n",
    "                    input_vocab_size=eng_vocab_size, target_vocab_size=spa_vocab_size,\n",
    "                    max_len=MAX_SEQ_LEN, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(27593, 512)\n",
       "  (decoder_embedding): Embedding(46821, 512)\n",
       "  (pos_embedding): PositionalEmbedding()\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderSubLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ffn): PositionFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (droupout1): Dropout(p=0.1, inplace=False)\n",
       "        (droupout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x DecoderSubLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=512, out_features=46821, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Imprimir los nombres de los módulos\\nfor name, module in model.named_modules():\\n    print(name)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Imprimir los nombres de los módulos\n",
    "for name, module in model.named_modules():\n",
    "    print(name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel, dataloader = accelerator.prepare(model, dataloader)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = get_peft_model(model, lora_config) #lora\n",
    "'''\n",
    "\n",
    "'''\n",
    "model, dataloader = accelerator.prepare(model, dataloader)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device) #para usar accelerate sin esto segun ejemplo\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, dataloader, loss_function, optimiser, epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch: 0/10, Loss: 3.5999\n",
    "Epoch: 1/10, Loss: 2.2048\n",
    "Epoch: 2/10, Loss: 1.7038\n",
    "Epoch: 3/10, Loss: 1.3771\n",
    "Epoch: 4/10, Loss: 1.1262\n",
    "Epoch: 5/10, Loss: 0.9241\n",
    "Epoch: 6/10, Loss: 0.7595\n",
    "Epoch: 7/10, Loss: 0.6307\n",
    "Epoch: 8/10, Loss: 0.5358\n",
    "Epoch: 9/10, Loss: 0.4685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_indices(sentence, word2idx):\n",
    "    return [word2idx.get(word, word2idx['<unk>']) for word in sentence.split()]\n",
    "\n",
    "def indices_to_sentence(indices, idx2word):\n",
    "    return ' '.join([idx2word[idx] for idx in indices if idx in idx2word and idx2word[idx] != '<pad>'])\n",
    "\n",
    "def translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
    "    model.eval()\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    input_indices = sentence_to_indices(sentence, eng_word2idx)\n",
    "    input_tensor = torch.tensor(input_indices).unsqueeze(0).to(device)\n",
    "\n",
    "    # Initialize the target tensor with <sos> token\n",
    "    tgt_indices = [spa_word2idx['<sos>']]\n",
    "    tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_len):\n",
    "            output = model(input_tensor, tgt_tensor)\n",
    "            output = output.squeeze(0)\n",
    "            next_token = output.argmax(dim=-1)[-1].item()\n",
    "            tgt_indices.append(next_token)\n",
    "            tgt_tensor = torch.tensor(tgt_indices).unsqueeze(0).to(device)\n",
    "            if next_token == spa_word2idx['<eos>']:\n",
    "                break\n",
    "\n",
    "    return indices_to_sentence(tgt_indices, spa_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_translations(model, sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device='cpu'):\n",
    "    for sentence in sentences:\n",
    "        translation = translate_sentence(model, sentence, eng_word2idx, spa_idx2word, max_len, device)\n",
    "        print(f'Input sentence: {sentence}')\n",
    "        print(f'Traducción: {translation}')\n",
    "        print()\n",
    "\n",
    "# Example sentences to test the translator\n",
    "test_sentences = [\n",
    "    \"Hello, how are you?\",\n",
    "    \"I am learning artificial intelligence.\",\n",
    "    \"Artificial intelligence is great.\",\n",
    "    \"Good night!\",\n",
    "    \"The cat is on the mat.\",\n",
    "    \"The small dog quickly ran away.\",\n",
    "    \"We will meet on Monday at 3 PM.\"\n",
    "]\n",
    "\n",
    "# Assuming the model is trained and loaded\n",
    "# Set the device to 'cpu' or 'cuda' as needed\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Evaluate translations\n",
    "evaluate_translations(model, test_sentences, eng_word2idx, spa_idx2word, max_len=MAX_SEQ_LEN, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input sentence: Hello, how are you?\n",
    "Traducción: <sos> hola que tal <eos>\n",
    "\n",
    "Input sentence: I am learning artificial intelligence.\n",
    "Traducción: <sos> estoy aprendiendo inteligencia artificial <eos>\n",
    "\n",
    "Input sentence: Artificial intelligence is great.\n",
    "Traducción: <sos> la inteligencia artificial esta estupenda <eos>\n",
    "\n",
    "Input sentence: Good night!\n",
    "Traducción: <sos> buenas noches <eos>\n",
    "\n",
    "Input sentence: The cat is on the mat.\n",
    "Traducción: <sos> el gato esta en la estera <eos>\n",
    "\n",
    "Input sentence: The small dog quickly ran away.\n",
    "Traducción: <sos> el perrito corriendo rapidamente <eos>\n",
    "\n",
    "Input sentence: We will meet on Monday at 3 PM.\n",
    "Traducción: <sos> nos veremos las pm a las seis <eos>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chatgpt: Claro, aquí están las traducciones al español para las frases que proporcionaste:\n",
    "Inglés: \"Hello, how are you?\"\n",
    "Español: \"Hola, ¿cómo estás?\"\n",
    "Inglés: \"I am learning artificial intelligence.\"\n",
    "Español: \"Estoy aprendiendo inteligencia artificial.\"\n",
    "Inglés: \"Artificial intelligence is great.\"\n",
    "Español: \"La inteligencia artificial es genial.\"\n",
    "Inglés: \"Good night!\"\n",
    "Español: \"¡Buenas noches!\"\n",
    "Inglés: \"The cat is on the mat.\"\n",
    "Español: \"El gato está en la alfombra.\"\n",
    "Inglés: \"The small dog quickly ran away.\"\n",
    "Español: \"El perro pequeño se alejó rápidamente.\"\n",
    "Inglés: \"We will meet on Monday at 3 PM.\"\n",
    "Español: \"Nos encontraremos el lunes a las 3 PM.\"\n",
    "Espero que estas traducciones sean útiles para tu test. Si necesitas algo más, ¡no dudes en preguntar!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
