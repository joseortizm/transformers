{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformer import Transformer\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom peft import LoraConfig, get_peft_model\\nlora_config = LoraConfig(\\n    r=8,  # Rangos bajos para LoRA\\n    lora_alpha=16,\\n    lora_dropout=0.1,\\n    target_modules= ['W_q', 'W_k', 'W_v', 'W_o']\\n)\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from peft import LoraConfig, get_peft_model\n",
    "# Configurar LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Rango bajo para LoRA\n",
    "    lora_alpha=32,  # Factor de escala\n",
    "    lora_dropout=0.1,  # Dropout\n",
    "    #bias=\"none\",  # Bias para LoRA \n",
    "    target_modules= ['W_q', 'W_k', 'W_v', 'W_o']\n",
    ")\n",
    "'''\n",
    "\n",
    "'''\n",
    "from accelerate import Accelerator\n",
    "accelerator = Accelerator()\n",
    "device = accelerator.device\n",
    "print(device)\n",
    "'''\n",
    "\n",
    "'''\n",
    "from peft import LoraConfig, get_peft_model\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # Rangos bajos para LoRA\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules= ['W_q', 'W_k', 'W_v', 'W_o']\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # \"encoder.layers.*.self_attn.W_q\",  \n",
    " #   \"encoder.layers.*.self_attn.W_k\",  \n",
    " #   \"encoder.layers.*.self_attn.W_v\",  \n",
    " #   \"encoder.layers.*.self_attn.W_o\",  \n",
    " #   \"decoder.layers.*.self_attn.W_q\",\n",
    " #   \"decoder.layers.*.self_attn.W_k\",\n",
    " #   \"decoder.layers.*.self_attn.W_v\",\n",
    " #   \"decoder.layers.*.self_attn.W_o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "#ignorar (es original del video)\n",
    "torch.manual_seed(23)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../datasets/idiomas-engl-span.tsv'\n",
    "\n",
    "with open(PATH, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "pairs_engl_span = [line.strip().split('\\t') for line in lines if '\\t' in line]\n",
    "#print(pairs_engl_span[:5])\n",
    "\n",
    "engl_sentences = [pair[1] for pair in pairs_engl_span]\n",
    "span_sentences = [pair[3] for pair in pairs_engl_span]\n",
    "#print(engl_sentences[:10])\n",
    "#print(span_sentences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265486\n",
      "265486\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[á]+\", \"a\", sentence)\n",
    "    sentence = re.sub(r\"[é]+\", \"e\", sentence)\n",
    "    sentence = re.sub(r\"[í]+\", \"i\", sentence)\n",
    "    sentence = re.sub(r\"[ó]+\", \"o\", sentence)\n",
    "    sentence = re.sub(r\"[ú]+\", \"u\", sentence)\n",
    "    sentence = re.sub(r\"[^a-z]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = '<sos> ' + sentence + ' <eos>'\n",
    "    return sentence\n",
    "#s1 = '¿Hola @ cómo estás? 123'\n",
    "#print(s1)\n",
    "#print(preprocess_sentence(s1))\n",
    "\n",
    "engl_sentences = [preprocess_sentence(sentence) for sentence in engl_sentences]\n",
    "span_sentences = [preprocess_sentence(sentence) for sentence in span_sentences]\n",
    "#print(engl_sentences[:10])\n",
    "#print(span_sentences[:10])\n",
    "print(len(engl_sentences))\n",
    "print(len(span_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences):\n",
    "    words = [word for sentence in sentences for word in sentence.split()]\n",
    "    word_count = Counter(words)\n",
    "    sorted_word_counts = sorted(word_count.items(), key=lambda x:x[1], reverse=True)\n",
    "    word2idx = {word: idx for idx, (word, _) in enumerate(sorted_word_counts, 2)}\n",
    "    word2idx['<pad>'] = 0\n",
    "    word2idx['<unk>'] = 1\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "    return word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_word2idx, eng_idx2word = build_vocab(engl_sentences)\n",
    "spa_word2idx, spa_idx2word = build_vocab(span_sentences)\n",
    "eng_vocab_size = len(eng_word2idx)\n",
    "spa_vocab_size = len(spa_word2idx)\n",
    "#print(eng_vocab_size, spa_vocab_size)\n",
    "#print(eng_idx2word)\n",
    "#print(spa_idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EngSpaDataset(Dataset):\n",
    "    def __init__(self, eng_sentences, spa_sentences, eng_word2idx, spa_word2idx):\n",
    "        self.eng_sentences = eng_sentences\n",
    "        self.spa_sentences = spa_sentences\n",
    "        self.eng_word2idx = eng_word2idx\n",
    "        self.spa_word2idx = spa_word2idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.eng_sentences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        eng_sentence = self.eng_sentences[idx]\n",
    "        spa_sentence = self.spa_sentences[idx]\n",
    "        # return tokens idxs\n",
    "        eng_idxs = [self.eng_word2idx.get(word, self.eng_word2idx['<unk>']) for word in eng_sentence.split()]\n",
    "        spa_idxs = [self.spa_word2idx.get(word, self.spa_word2idx['<unk>']) for word in spa_sentence.split()]\n",
    "        \n",
    "        return torch.tensor(eng_idxs), torch.tensor(spa_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    eng_batch, spa_batch = zip(*batch)\n",
    "    eng_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in eng_batch]\n",
    "    spa_batch = [seq[:MAX_SEQ_LEN].clone().detach() for seq in spa_batch]\n",
    "    eng_batch = torch.nn.utils.rnn.pad_sequence(eng_batch, batch_first=True, padding_value=0)\n",
    "    spa_batch = torch.nn.utils.rnn.pad_sequence(spa_batch, batch_first=True, padding_value=0)\n",
    "    return eng_batch, spa_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, loss_function, optimiser, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0 \n",
    "        for i, (eng_batch, spa_batch) in enumerate(dataloader):\n",
    "            eng_batch = eng_batch.to(device)\n",
    "            spa_batch = spa_batch.to(device)\n",
    "            # Decoder preprocessing\n",
    "            target_input = spa_batch[:, :-1]\n",
    "            target_output = spa_batch[:, 1:].contiguous().view(-1)\n",
    "            # Zero grads\n",
    "            optimiser.zero_grad()\n",
    "            # run model\n",
    "            output = model(eng_batch, target_input)\n",
    "            output = output.view(-1, output.size(-1))\n",
    "            # loss\\\n",
    "            loss = loss_function(output, target_output)\n",
    "            # gradient and update parameters\n",
    "            loss.backward()\n",
    "            #accelerator.backward(loss) #para accelerate\n",
    "            optimiser.step()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        avg_loss = total_loss/len(dataloader)\n",
    "        print(f'Epoch: {epoch}/{epochs}, Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32#64\n",
    "dataset = EngSpaDataset(engl_sentences, span_sentences, eng_word2idx, spa_word2idx)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(d_model=512, num_heads=8, d_ff=2048, num_layers=6,\n",
    "                    input_vocab_size=eng_vocab_size, target_vocab_size=spa_vocab_size,\n",
    "                    max_len=MAX_SEQ_LEN, dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder_embedding): Embedding(27593, 512)\n",
       "  (decoder_embedding): Embedding(46821, 512)\n",
       "  (pos_embedding): PositionalEmbedding()\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderSubLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ffn): PositionFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (droupout1): Dropout(p=0.1, inplace=False)\n",
       "        (droupout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x DecoderSubLayer(\n",
       "        (self_attn): MultiHeadAttention(\n",
       "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (cross_attn): MultiHeadAttention(\n",
       "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (feed_forward): PositionFeedForward(\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (output_layer): Linear(in_features=512, out_features=46821, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Imprimir los nombres de los módulos\\nfor name, module in model.named_modules():\\n    print(name)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Imprimir los nombres de los módulos\n",
    "for name, module in model.named_modules():\n",
    "    print(name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel, dataloader = accelerator.prepare(model, dataloader)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = get_peft_model(model, lora_config) #lora\n",
    "'''\n",
    "\n",
    "'''\n",
    "model, dataloader = accelerator.prepare(model, dataloader)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device) #para usar accelerate sin esto segun ejemplo\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 0\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 1\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 2\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 3\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 4\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 5\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 6\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 7\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 8\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 9\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 10\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 11\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 12\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 13\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 14\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 15\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 16\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 17\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 18\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 19\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 20\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 21\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 22\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 23\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 24\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 25\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 26\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 27\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 28\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 29\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 30\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 31\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 32\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 33\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 34\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 35\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 36\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 37\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 38\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 39\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 40\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 41\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 42\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 43\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 44\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 45\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 46\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 47\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 48\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 49\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 50\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 51\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 52\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 53\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 54\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 55\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 56\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 57\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 58\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 59\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 60\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 61\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 62\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 63\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 64\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 65\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 66\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 67\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 68\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 69\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 70\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 71\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 72\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 73\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 74\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 75\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 76\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 77\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 78\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 79\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 80\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 81\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 82\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 83\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 84\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 85\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 86\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 87\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 88\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 89\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 90\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 91\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 92\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 93\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 94\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 95\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 96\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 97\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 98\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 99\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 100\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 101\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 102\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 103\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 104\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 105\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 106\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 107\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 108\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 109\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 110\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 111\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 112\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 113\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 114\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 115\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 116\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 117\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 118\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 119\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 120\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 121\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 122\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 123\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 124\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 125\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 126\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 127\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 128\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 129\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 130\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 131\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 132\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 133\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 134\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 135\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 136\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 137\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 138\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 139\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 140\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 141\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 142\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 143\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 144\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 145\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 146\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 147\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 148\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 149\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 150\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 151\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 152\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 153\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 154\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 155\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 156\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 157\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 158\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 159\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 160\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 161\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 162\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 163\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 164\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 165\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 166\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 167\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 168\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 169\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 170\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 171\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 172\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 173\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 174\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 175\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 176\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 177\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 178\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 179\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 180\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 181\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 182\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 183\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 184\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 185\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 186\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 187\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 188\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 189\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 190\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 191\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 192\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 193\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 194\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 195\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 196\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 197\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 198\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 199\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 200\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 201\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 202\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 203\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 204\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 205\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 206\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 207\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 208\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 209\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 210\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 211\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 212\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 213\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 214\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 215\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 216\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 217\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 218\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 219\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 220\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 221\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 222\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 223\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 224\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 225\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 226\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 227\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 228\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 229\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 230\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 231\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 232\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 233\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 234\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 235\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 236\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 237\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 238\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 239\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 240\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 241\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 242\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 243\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 244\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 245\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 246\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 247\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 248\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 249\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 250\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 251\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 252\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 253\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 254\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 255\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 256\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 257\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 258\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 259\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 260\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 261\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 262\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 263\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 264\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 265\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 266\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 267\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 268\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 269\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 270\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 271\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 272\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 273\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 274\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 275\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 276\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 277\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 278\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 279\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 280\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 281\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 282\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 283\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 284\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 285\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 286\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 287\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 288\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 289\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 290\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 291\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 292\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 293\n",
      "here 5\n",
      "here 6\n",
      "here 1\n",
      "here 2\n",
      "here 3\n",
      "here 4\n",
      "i: 294\n",
      "here 5\n",
      "here 6\n",
      "here 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 3.35 GB, other allocations: 14.25 GB, max allowed: 18.13 GB). Tried to allocate 611.55 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, loss_function, optimiser, epochs)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# run model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhere 1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43meng_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhere 2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniforge3/envs/myclone/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/myclone/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Streaming/YouTube/transformers/transformer.py:341\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, source, target)\u001b[0m\n\u001b[1;32m    338\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embedding(target)\n\u001b[1;32m    339\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(target, encoder_output, target_mask, source_mask) \u001b[38;5;66;03m#Create Decoder. source_mask is encoder_mask \u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/myclone/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/myclone/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/myclone/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 3.35 GB, other allocations: 14.25 GB, max allowed: 18.13 GB). Tried to allocate 611.55 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "train(model, dataloader, loss_function, optimiser, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4149"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
